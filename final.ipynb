{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a41a6d-6d1a-45aa-8a9e-e92e65a3c685",
   "metadata": {},
   "source": [
    "# 빅데이터컴퓨팅 기말고사 \n",
    "* ※ 시험 일시 : 6월 18일 오후 2시~ 2시 50 ※ 시험 범위 : \n",
    " -\t9장 : 선 그래프, 막대그래프, 히스토그램, 산포도(산점도), 산포도 행렬\n",
    " import matplotlib.pyplot as plt, import seaborn as sn plt.subplots(), plt.plot(), plt.scatter(), plt.bar(), plt.hist(), plt.savefig(), sn.pairplot()\n",
    " -\t10장: 데이터 집계와 그룹 연산(10.1, 10.2, 10.3, 10.5)\n",
    "import pandas as pd, df.groupby(), df.groupby().apply(), df.pivot_table()\n",
    " -\t11장 : 시계열의 이동창 함수 (11.7), rolling()\n",
    " -\t12장 : 데이터분석의 파이썬 모델링 프로그래밍(12.1, 12.4)\n",
    " -\t13장 : 데이터 분석 사례 – 영화 평점 데이터 분석 모델링\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776c172-e08e-4b6b-b264-a34842c42713",
   "metadata": {},
   "source": [
    "# (9장)\n",
    "# 1번\t\n",
    "* 다음은 변수 유형별 그래프 시각화에 대한 설명이다. 빈칸에 알맞은 단어를 넣어 완성하시 오.\n",
    " ( ①     선    ) 그래프는 ‘연속형 변수 값’들을 직선이나 곡선으로 연결하여 데이터 사이의 관계를 나타낸다. ( ②    산포도    )그래프는 서로 다른 ‘두 연속형 변수’ 사이 의 관계를 나타내며 연속형 변수의 상관성을 확인할 수 있다. ( ③     막대    )그래프는 ‘집 단별 차이를 표현’할 때 사용하며 데이터 값의 크기에 비례하여 높이를 갖는 직사각형 막 대로 표현한다. ( ④       히스토그램      ) 그래프는 ‘변수가 하나인 데이터의 빈도 수’를 그래프로 표현하며 구간을 나누는 간격의 크기에 따라 빈도 모양이 변한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8230ff-4785-4055-8bdb-0a9f818af470",
   "metadata": {},
   "source": [
    "# 10장 2번 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc91d73c-4f3a-4ced-a2c9-555415ed8a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID Product  Quantity\n",
      "0         C1       A        10\n",
      "1         C2       B        15\n",
      "2         C3       A        10\n",
      "3         C4       B        20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'CustomerID':['C1','C2','C3','C4'],\n",
    "                   'Product':['A','B','A','B'],\n",
    "                   'Quantity':[10,15,10,20]})\n",
    "# result = df.pivot_table(values='Quantity',index = 'Product', aggfunc='sum')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4075d20-8cf4-4328-80ad-77ca4f4f4427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Quantity\n",
      "Product          \n",
      "A              20\n",
      "B              35\n"
     ]
    }
   ],
   "source": [
    "# (2-1)\t각 제품(Product)별로 판매된 총 수량(Quantity)을 계산하여 그 결과를 출력하시오.\n",
    "pivot_table_1 = df.pivot_table(index='Product', values='Quantity', aggfunc='sum')\n",
    "print(pivot_table_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "066f8dcb-8421-45f8-b64d-1aae085a6e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product        A     B\n",
      "CustomerID            \n",
      "C1          10.0   NaN\n",
      "C2           NaN  15.0\n",
      "C3          10.0   NaN\n",
      "C4           NaN  20.0\n"
     ]
    }
   ],
   "source": [
    "# (2-2)\t각 고객(CustomerID)이 구매한 제품(Product)별 총 수량(Quantity)을 구하고, 그 결과 를 출력하시오.\n",
    "pivot_table_2 = df.pivot_table(index='CustomerID', columns='Product', values='Quantity', aggfunc='sum')\n",
    "print(pivot_table_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da13812e-5d14-4174-beda-626fb4b46319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Quantity\n",
      "Product          \n",
      "A            10.0\n",
      "B            17.5\n"
     ]
    }
   ],
   "source": [
    "# (2-3) 각 제품(Product)별로 평균 구매 수량(Quantity)을 계산하여 출력\n",
    "pivot_table_3 = df.pivot_table(index='Product', values='Quantity', aggfunc='mean')\n",
    "print( pivot_table_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534f027-6e2b-4fbc-ba7e-1b4202cb84a4",
   "metadata": {},
   "source": [
    "# 3번 \n",
    "* [코딩 문제] 다음은 주어진 데이터프레임 “df”에 대해 groupby()와 apply() 함수을 사용하 여 “각 도시에서 최고 온도가 가장 높은 날짜를 찾는” 코드를 작성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dfb9dd2-dc17-4e70-8945-b000060c6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   도시          날짜  최고 온도  최저 온도\n",
      "0  서울  2024-06-01     28     18\n",
      "1  서울  2024-06-02     30     20\n",
      "2  대구  2024-06-01     32     21\n",
      "3  광주  2024-06-01     29     19\n",
      "\n",
      "            날짜  최고 온도  최저 온도\n",
      "도시                          \n",
      "광주  2024-06-01     29     19\n",
      "대구  2024-06-01     32     21\n",
      "서울  2024-06-02     30     20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khgg0\\AppData\\Local\\Temp\\ipykernel_24596\\3696923810.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result = df.groupby('도시').apply(lambda x: x.loc[x['최고 온도'].idxmax()][1:])\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'도시':['서울','서울','대구','광주'],\n",
    "                   '날짜':['2024-06-01','2024-06-02','2024-06-01','2024-06-01'],\n",
    "                   '최고 온도':[28,30,32,29],\n",
    "                   '최저 온도':[18,20,21,19]})\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# idxmax() 함수는 시리즈에서 최대값을 갖는 요소의 인덱스를 반환하는 Pandas 함수\n",
    "result = df.groupby('도시').apply(lambda x: x.loc[x['최고 온도'].idxmax()][1:]) \n",
    "print(result)\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07cbef-259b-460d-add3-c81f8c82d711",
   "metadata": {},
   "source": [
    "# 11장\n",
    "# 4번\t\n",
    "* [코딩문제] 다음은 일별 주식 가격 데이터를 포함하는 시계열 데이터 분석이다(①,②). 이동 창 함수 rolling()을 이용하여 2일 이동 합계를 계산하고(③), 이 결과를 데이터프레임에 새로 운 열로 추가하고(③), 최종 데이터프레임을 출력(④)하는 코딩을 완성하시오\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0382c3ee-a4a5-4e2e-ae00-8174ddb8f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             종가  2일 이동 합계\n",
      "날짜                       \n",
      "2024-06-01  100       NaN\n",
      "2024-06-02  102     202.0\n",
      "2024-06-03  101     203.0\n",
      "2024-06-04  105     206.0\n",
      "2024-06-05  107     212.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 주어진 데이터프레임\n",
    "data = {\n",
    "    '날짜': ['2024-06-01', '2024-06-02', '2024-06-03', '2024-06-04', '2024-06-05'],\n",
    "    '종가': [100, 102, 101, 105, 107] } \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# '날짜' 열의 데이터를 datetime 형식으로 변환(1)\n",
    "df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "# '날짜' 열을 데이터프레임 df의 인덱스로 설정(2)\n",
    "df.set_index('날짜',inplace=True)\n",
    "# 2일 이동 합계 계산하여 새로운 열 '2일 이동 합계'로 데이터프레임 df에 추가(3)\n",
    "# rolling() 함수를 사용하면 이동 평균, 이동 합, 이동 표준편차 등을 계산할 수 있습니다\n",
    "df['2일 이동 합계'] = df['종가'].rolling(window=2).sum()                                    \n",
    "# 최종 데이터프레임 출력(4)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a6fb6b-e324-4b81-a099-00621e934260",
   "metadata": {},
   "source": [
    "# 5번\n",
    "* Pandas 데이터프레임 df에서 결측 데이터의 처리 단계를 설명하고, 결측 데이터의 개수를 확인하는 함수, \n",
    "결측 데이터 제거하는 함수, 결측 데이터 대체하는 함수를 각각 적으시오.\n",
    "* 결측 데이터 확인->결측 데이터 처리 방법 결정(dropna(),fillna())->결측 데이터 처리->처리 결과 확인\n",
    "* 결측 데이터의 개수를 확인하는 함수: df.isnull()\n",
    "* 결측 데이터 제거하는 함수: df.dropna()\n",
    "* 결측 데이터 대체하는 함수: df.fillna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddcc123-e7ee-4873-aa4c-bc49f2e5f840",
   "metadata": {},
   "source": [
    "# 6번\n",
    "* Pandas 데이터프레임 df에서 중복 데이터의 처리 단계를 설명하고, 중복 데이터가 있는지 를 확인하는 함수, 중복 데이터 제거하는 함수를 각각 적으시오.\n",
    "* 중복 데이터 확인->중복 데이터 처리 방법 결정->중복 데이터 처리->처리 결과 확인\n",
    "* 중복 데이터 확인 함수: df.duplicated()\n",
    "* 중복 데이터 제거 함수: df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5a90b-7311-4d55-8a0a-43579046add8",
   "metadata": {},
   "source": [
    "# 7번\n",
    "* 머신러닝 알고리즘은 범주형 데이터를 처리하기 위해 원-핫 인코딩(One-hot encoding) 형태로 변환해주는 전처리가 필요하다. 원-핫 인코딩에 대해 설명하시오\n",
    "* 원-핫 인코딩은 범주형 데이터를 이진 벡터로 변환하여 각 범주를 별도의 열로 표현합니다. 각 범주가 나타나는 경우 해당 열에 1을,\n",
    "그렇지 않으면 0을 입력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db510064-24ae-4bdb-9e23-fe4e7e051e5a",
   "metadata": {},
   "source": [
    "# 8번\n",
    "* 다음 코드의 실행 결과를 적으시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56f0048f-4cd6-4220-8082-e40b8c2718ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  City     대구     서울     인천\n",
      "0   서울  False   True  False\n",
      "1   대구   True  False  False\n",
      "2   인천  False  False   True\n",
      "3   서울  False   True  False\n",
      "4   대구   True  False  False\n",
      "5   서울  False   True  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "cities = ['서울', '대구', '인천', '서울', '대구', '서울'] \n",
    "df = pd.DataFrame(cities, columns=['City']) \n",
    "encoded = pd.get_dummies(df['City']) \n",
    "df_encoded = pd.concat([df, encoded], axis=1) \n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11480c8f-e47c-4a63-a898-680fb2d4a133",
   "metadata": {},
   "source": [
    "# 9번\n",
    "* [코딩문제] 다음과 같이 데이터프레임 df(왼쪽 그림)에 대하여 pivot_table()을 활용하여  CustomerID와 Product별 총 구매 수량을 계산한 후,  stack() 함수를 활용하여 스택하여 MultiIndex Series로 변환하여 그 결과(오른쪽 그림)가 반영된 데이터프레임을 출력하도록  코딩시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "702c3a8e-d6dc-4f55-8b8f-442f8d102c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OrderID CustomerID Product  Quantity\n",
      "0        1         C1       A        10\n",
      "1        2         C2       B        15\n",
      "2        3         C3       A        10\n",
      "3        4         C4       B        20\n",
      "\n",
      "Product        A     B\n",
      "CustomerID            \n",
      "C1          10.0   NaN\n",
      "C2           NaN  15.0\n",
      "C3          10.0   NaN\n",
      "C4           NaN  20.0\n",
      "\n",
      "CustomerID  Product\n",
      "C1          A          10.0\n",
      "C2          B          15.0\n",
      "C3          A          10.0\n",
      "C4          B          20.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'OrderID':[1,2,3,4],\n",
    "                   'CustomerID':['C1','C2','C3','C4'],\n",
    "                   'Product':['A','B','A','B'],\n",
    "                   'Quantity':[10,15,10,20]})\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# pivot_table()을 활용하여 CustomerID와 Product별 총 구매 수량 계산\n",
    "pivot_df = df.pivot_table(index='CustomerID', columns='Product', values='Quantity', aggfunc='sum')\n",
    "print(pivot_df)\n",
    "print()\n",
    "\n",
    "# stack() 함수를 활용하여 MultiIndex Series로 변환\n",
    "stacked_df = pivot_df.stack()\n",
    "\n",
    "# 결과 출력\n",
    "print(stacked_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b88eb4-4a57-44ca-b3ab-57b84fbd9531",
   "metadata": {},
   "source": [
    "# 10번\n",
    "* 다음 중 데이터 분석에서 사용하지 않는 데이터 유형은 무엇인가? (a) 범주형 데이터   (b) 연속형 데이터\t(c) 이미지 데이터   (d) 시계열 데이터\n",
    "* 정답:c 이미지 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a4dc5d-da1a-41c0-b33b-91b04cc13edd",
   "metadata": {},
   "source": [
    "# 11번\n",
    "* 데이터 분석 파이프라인의 과정을 올바르게 작성한 것은 무엇인가?\n",
    "* (a) 데이터 준비-데이터 탐색-데이터 정제-데이터 분석-데이터 시각화\n",
    "* (b) 데이터 정제-데이터 준비-데이터 탐색-데이터 분석-데이터 시각화\n",
    "* (c) 데이터 정제-데이터 준비-데이터 분석-데이터 탐색-데이터 시각화\n",
    "* (d) 데이터 정제-데이터 준비-데이터 시각화 –데이터 탐색-데이터 분석\n",
    "* 정답: (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c738a-c94f-46b4-b640-208f38379f7b",
   "metadata": {},
   "source": [
    "# 12번\n",
    "* 데이터 분석의 모델링(데이터마이닝, 데이터사이언스)에 대한 설명이다. 설명이 가장 잘못 된 것은 무엇인가?\n",
    "* (a)\t데이터마이닝 모델링은 통계적 모델링이 아니므로 지나치게 통계적 가설이나 유의성에 집착하지 말아야 한다.\n",
    "* (b)\t모델링 방법은 여러 가지가 있으므로 모델링 시 반드시 다양한 옵션을 줘서 모델링을 수행하여 최고의 성과를 도출하여야 한다.\n",
    "* (c)\t분석 데이터를 학습 및 테스트 데이터로 7:3 또는 8:2 비율로 상황에 맞게 실시한다.\n",
    "* (d)\t성능에 집착하면 분석 모델링의 주목적인 실무 적용에 반하여 시간을 낭비할 수 있으므로 훈련 및 테스트 성능에 큰 편차가 없고 예상 성능을 만족하면 중단한다.\n",
    "* 정답: (b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a22ea-bc13-4e88-8f44-8f3e38798e8b",
   "metadata": {},
   "source": [
    "# 13번\n",
    "* 데이터 탐색의 목적은 데이터를 이해하는 것이다. 다음 중 이에 대한 설명으로 가장 부적절한 것은?\n",
    "* (a)\t데이터에 대한 전반적인 이해를 통해 분석 가능한 데이터인지 확인하는 단계이다.\n",
    "* (b)\t데이터 탐색 과정은 데이터에 포함된 변수의 유형이 어떻게 되는지를 찾아가는 과정이다.\n",
    "* (c)\t데이터를 시각화하는 것만으로는 결측치나 이상치 식별이 잘 되지 않는다.\n",
    "* (d) 기계 학습 알고리즘이 학습을 얼마나 잘 하느냐 하는 것은 전적으로 데이터의 품질과 데이터에 담긴 정보량에 달려 있다.\n",
    "* 정답: (c) 그래프로 시각화를 한다면 이상치를 식별하기가 쉽다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2c96b-43a7-44cb-a2c9-da22083dcba0",
   "metadata": {},
   "source": [
    "# 14번\n",
    "* 상관분석이 무엇인지 설명하시오.\n",
    "* 상관 분석은 확률론과 통계학에서 두 변수 간에 어떤 선형적 관계를 갖고 있는 지를 분석하는 방법이다. 두 변수는 서로 독립적인 관계이거나 상관된 관계일 수 있으며 이때 두 변수간의 관계의 강도를 상관관계(correlation)라 한다. 상관분석에서는 상관관계의 정도를 나타내는 단위로 모상관계수로 ρ를 사용하며 표본 상관 계수로 r 을 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f9789d-2f14-4dd9-beec-7e74a63471b4",
   "metadata": {},
   "source": [
    "# 15번\n",
    "* 최소제곱법이 무엇인지 설명하시오.\n",
    "* 최소제곱법이란, \"Least Square Method\" or \"Ordinary Least Square\"으로 불리며 오차를 최소화 시키는 방법으로 회귀 계수(β0,β1)를 추정하는 기법입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c9ec6-9ab4-470d-aba3-2b6cad5ec540",
   "metadata": {},
   "source": [
    "# 16번\n",
    "* 다음은 기계 학습 기반 예측 분석 모델링의 개발 과정에 포함되어지는 프로세스이다. 개 발 과정을 주어진 프로세스들을 사용하여 순서대로 나열해서 작성하시오. [데이터 탐색 및 시각화, 모델 선택, 모델 학습, 피처 선택 및 추출, 모델 평가, 데이터 수 집, 데이터 전처리, 모델 개선]\n",
    "* 1.데이터 수집 2.데이터 탐색 및 시각화 3.데이터 전처리 4.피처 선택 및 추출 5.모델 선택 6.모델 학습 7.모델 평가 8.모델 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb55711f-5c58-4867-9e0c-7f82ab498ed8",
   "metadata": {},
   "source": [
    "# 17번 \n",
    "* 기계 학습 모델에서 최적화(Optimization)와 일반화(Generalization)의 차이점을 데이터 관점에서 설명하시오.\n",
    "* 최적화는 주어진 훈련 데이터에 대해 모델 성능을 최대화하는 것이며, 일반화는 새로운 데이터에 대해 모델 성능을 유지하는 것입니다. 최적화는 훈련 데이터에 대한 모델의 적합성을 강조하며, 일반화는 테스트 데이터 또는 실제 데이터에 대한 모델의 성능을 강조합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df4e69-7eb5-421a-a9a9-819c7b940dca",
   "metadata": {},
   "source": [
    "# 18번\n",
    "* 머신러닝 학습 중 지도학습에 대해 예제를 가지고 설명하시오.\n",
    "* 지도학습(Supervised Learning)은 머신러닝의 한 유형으로, 입력 데이터와 그에 대한 정답(레이블)이 주어졌을 때, 입력 데이터를 정답과 일치시키도록 모델을 학습하는 방법입니다. 지도학습의 목표는 새로운 데이터가 주어졌을 때 올바른 출력을 예측할 수 있는 모델을 만드는 것입니다.\n",
    "* 지도학습의 예제: 주택 가격 예측\n",
    "문제 정의\n",
    "주어진 특징(예: 면적, 방 개수, 위치 등)에 따라 주택의 가격을 예측하는 모델을 만드는 것입니다.\n",
    "\n",
    "# 데이터셋\n",
    "* 입력 데이터(features): 주택의 다양한 특징을 나타내는 데이터\n",
    "면적 (평방미터)\n",
    "방의 개수\n",
    "위치 (위도, 경도)\n",
    "건축 연도 등\n",
    "* 출력 데이터(labels): 주택 가격 (예: $500,000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6650b4-5585-4890-af42-08718037e270",
   "metadata": {},
   "source": [
    "# 19번\n",
    "* 선형 회귀모델의 성능을 평가하는 방법에 대해 적으시오.\n",
    "* 평균 제곱 오차(Mean Squared Error, MSE), 평균 절대 오차(Mean Absolute Error, MAE), R^2(R-Squared), 평균 절대 백분율 오차 (Mean Absolute Percentage Error, MAPE)\n",
    "* 평균 제곱 오차(Mean Squared Error, MSE): MSE는 실제 값과 예측 값의 차이를 제곱한 값들의 평균을 구한 것입니다. 제곱을 하기 때문에 큰 오차에 대해 더 큰 패널티를 부여합니다.\n",
    "* 평균 절대 오차 (Mean Absolute Error, MAE): MAE는 실제 값과 예측 값의 차이의 절대값을 구한 후 그 값들의 평균을 구한 것입니다. MAE는 오차의 절대 크기를 평균하여 모델의 성능을 평가합니다.\n",
    "* 결정 계수 (R-squared, 𝑅^2) : 𝑅^2는 모델이 실제 데이터를 얼마나 잘 설명하는지를 나타내는 지표입니다. 1에 가까울수록 모델이 데이터를 잘 설명한다는 의미입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa647e-56e7-4423-9c95-225d9afdefc0",
   "metadata": {},
   "source": [
    "# 20번\n",
    "* 분류 모델을 평가하는 정확도(accuracy)에 대해 설명하시오.\n",
    "* 분류 모델을 평가하는 정확도(Accuracy)는 모델이 올바르게 예측한 샘플의 비율을 측정하는 지표입니다. 정확도는 전체 예측 중에서 맞춘 예측의 비율을 나타내며, 가장 직관적이고 널리 사용되는 평가 지표 중 하나입니다.\n",
    "* 정확도는 다음과 같이 정의됩니다: 정확도 (Accuracy)=올바르게 예측한 샘플 수(TP+TN) / 전체 샘플 수 정확도(TP+TN+FP+FN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5e40e-4983-416f-950c-aa87139295e0",
   "metadata": {},
   "source": [
    "# 21번\n",
    "* 다음은 기계학습 모델링에 관련된 문제들이다. 빈칸에 알맞은 단어를 넣어 완성하시오.\n",
    "* (21-1)\t지도학습 알고리즘에는 크게 (       회귀      )와 (        분류           )의 두 가지 유 형이 있다. 전자는 연속적인 값을 예측하고, 후자는 어떤 범주 중의 하나로 예측한다.\n",
    "* (21-2)\t( sklearn                              )은 파이썬 \n",
    "언어에서 기계학습을 수행하는 대표적인 라이브러리이다. 이 라이브러리는  선형회귀, 로지스 틱회귀 등의 분류, 회귀 알고리즘을 포함하고 있다.\n",
    "* (21-3)\t사이킷런에서는 선형회귀를 위해 선형 모델 linear_model을 import한 뒤에 (LinearRegression()                 )을 통해 선형회귀 모델을 생성한 다.\n",
    "* (21-4)\t사이킷런에서 입력 2차원 배열 X와 출력 벡터 y가 있을 경우, 이 값들을 이용하여 선 형 회귀 분석을 지도학습하려면 (  fit             )함수 에 X, y를 전달한다.\n",
    "* (21-5)\t사이킷런의 선형 모델에서 입력 값을 사용하여 출력을 예측하는 함수는\n",
    " (        predict        )이다. 이 함수의 매개변수는 예측 에 필요한 입력 데이터이다. 이 입력 데이터의 형태는 선형회귀 지도학습을 할 때 사용한 입 력과 같이 2차원 배열이다.\n",
    "* (21-6)\t학습 데이터와 테스트 데이터를 분리하기 위해서는 사이킷런에서 제공하는 (train_test_split)이라는 함수를 사용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1599d05-f9fb-4dc2-a748-3021f547c0a4",
   "metadata": {},
   "source": [
    "# 22번\n",
    "* 교차 검증(Cross-validation)은 무엇이며, 왜 중요한가요?\n",
    "* 교차 검증(Cross-validation)은 모델의 성능을 평가하고 일반화 성능을 추정하기 위해 데이터를 여러 개의 훈련 세트와 테스트 세트로 나누어 모델을 학습하고 평가하는 기법입니다. 가장 일반적으로 사용되는 방법은 K-겹 교차 검증(K-fold Cross-validation)입니다.\n",
    "* 왜 중요하냐면\n",
    "* 과적합 방지: 단순히 하나의 훈련 세트와 테스트 세트를 사용하는 경우, 특정 데이터 분할에 따라 모델의 성능이 과대평가되거나 과소평가될 수 있습니다. 교차 검증은 여러 번의 평가를 통해 이러한 편향을 줄여줍니다.\n",
    "* 일반화 성능 추정: 교차 검증은 모델이 새로운 데이터에 대해 얼마나 잘 일반화될 수 있는지를 더 정확하게 추정할 수 있게 해줍니다.\n",
    "* 데이터 효율성: 데이터를 효율적으로 사용하여 모델을 평가할 수 있습니다. 특히 데이터셋이 작은 경우, 더 많은 데이터를 훈련에 사용할 수 있어 유리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92630451-753d-4d1a-bbd6-48595a6ae98d",
   "metadata": {},
   "source": [
    "# 23번\n",
    "* 다음 중 가장 일반적인 분류 문제 평가 지표는 무엇인가요?\n",
    "* (a) AUC-ROC 곡선 아래 면적    (b) R 제곱 값\n",
    "(c) 평균 제곱 오차 (MSE)        (d) 정확도 (Accuracy)\n",
    "* (d) 정확도(Accuracy) 정확도는 분류 문제에서 모델이 올바르게 예측한 샘플의 비율을 나타내는 지표로, 가장 일반적이고 직관적인 분류 문제 평가 지표입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0510c7-7759-4946-930e-aa917a6df1c8",
   "metadata": {},
   "source": [
    "# 24번\n",
    "* 다음 중 overfitting을 방지하기 위한 방법이 아닌 것은?\n",
    "* (a) 더 많은 데이터 수집   (b) 모델의 복잡성 증가\n",
    "  (c) 특성 선택 (Feature selection)  (d) 교차 검증 사용\n",
    "* 정답: (b) 모델의 복잡성 증가   overfitting을 방지하려면 모델의 복잡성을 줄이는 것이 일반적이다. 모델의 복잡성을 증가시키면 학습 데이터에 과적합될 가능성이 높아진다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cee15b-037a-4775-afc2-ecdbfb5666ce",
   "metadata": {},
   "source": [
    "# 25번\n",
    "* 다음 중 기계 학습 모델의 일반화를 평가하는 데 가장 적합한 방법은 무엇인가요?\n",
    "* (a) 훈련 데이터셋의 정확도 평가    (b) 테스트 데이터셋의 정확도 평가\n",
    "  (c) 모델의 학습 속도 평가   (d) 모델의 파라미터 수 평가\n",
    "* (b) 테스트 데이터셋의 정확도 평가  일반화를 평가하기 위해서는 모델이 보지 못한 새로운 데이터에 대해 얼마나 잘 예측하는지를 평가해야 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea788c-2f8e-4c09-988f-229fe1db68bd",
   "metadata": {},
   "source": [
    "# 26번\n",
    "* 다음 중 overfitting을 나타내는 전형적인 양상은 무엇인가요?\n",
    "* (a) 훈련 데이터와 테스트 데이터에서 모두 높은 정확도를 보인다.\n",
    "* (b) 훈련 데이터에서 매우 높은 정확도를 보이지만 테스트 데이터에서 낮은 정확도를 보인다.\n",
    "* (c) 훈련 데이터에서 낮은 정확도를 보이고 테스트 데이터에서 높은 정확도를 보인다.\n",
    "* (d) 훈련 데이터와 테스트 데이터에서 모두 낮은 정확도를 보인다.\n",
    "* 정답: (b)가  Overfitting은 모델이 학습 데이터에 너무 맞춰져서 새로운 데이터(테스트  데이터)에서는 성능이 저하되는 현상 이는 모델이 학습 데이터의 노이즈까지 학습했기 때문에 발생한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c6cd4-18c3-4f2c-a83b-e6aa2a78929e",
   "metadata": {},
   "source": [
    "# 27번\n",
    "* 다음 중 기계 학습 모델의 일반화 성능을 향상시키는 방법으로 적절하지 않은 것은 무엇 인가요?\n",
    "* (a) 더 많은 훈련 데이터를 수집한다. (b) 모델의 복잡도를 증가시킨다. (c) 정규화를 사용한다. (d) 교차 검증을 수행한다.\n",
    "* 정답: (b) 모델의 복잡도를 증가시키면 과적합의 위험이 커진다.  복잡한 모델은 훈련 데이터에 너무 잘 맞아 새로운 데이터에 대한 일반화 성능이 떨어질 수 있다. 일반화 성능을 향상시키기 위해서는 모델의 복잡도를 적절히 제어하는 것이 중요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc98e9fd-4d81-437c-899c-842f9a48f5f1",
   "metadata": {},
   "source": [
    "# 28번\n",
    "* 다음 중 overfitting을 피하기 위해 사용할 수 있는 기술이 아닌 것은?\n",
    "* (a) 정규화 (Regularization)           (b) 원-핫 인코딩(One-hot encoding)\n",
    "  (c) 데이터 증강 (Data Augmentation)   (d) 모델 파라미터 최적화\n",
    "\n",
    "* 정답:(b) 원-핫 인코딩 - 범주형 데이터를 수치형으로 변환하는 기술로 overfitting을 방지하는 목적 자체는 아님"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1effba62-8b19-4c05-ab5e-70ee315f7753",
   "metadata": {},
   "source": [
    "# 29\n",
    "* 다음은 회귀 분석 모델의 성능 평가 지표인 MSE(Mean Squared Error), MAE(Mean\n",
    "Absolute Error), R²(Coefficient of Determination)에 관련된 문제이다.\n",
    "* (29-1) MSE에 대해 설명하시오.\n",
    "* MSE는 실제 값과 예측 값 사이의 차이(오차)를 제곱한 값의 평균을 나타냅니다.\n",
    "* (29-2)MAE에 대해 설명하시오.\n",
    "* MAE는 실제 값과 예측 값 사이의 차이(오차)의 절대값의 평균을 나타냅니다.\n",
    "* (29-3) 이상치가 많은 데이터 셋에서는 MSE 또는 MAE 중 어느 것을 사용하는 것이 더 유리한지 적으시오.\n",
    "* 이상치가 많은 데이터 셋에서는 **MAE(Mean Absolute Error, 평균 절대 오차)**를 사용하는 것이 더 유리합니다.\n",
    "* 이상치에 대한 민감도: MSE(Mean Squared Error, 평균 제곱 오차)는 오차를 제곱하여 계산하므로, 큰 오차(이상치)의 영향이 매우 큽니다. 이상치가 존재할 경우, MSE 값이 급격히 증가할 수 있습니다. 반면, MAE는 오차의 절대값을 사용하므로, 이상치의 영향이 상대적으로 적습니다.\n",
    "\n",
    "* 안정성: 이상치가 많은 데이터셋에서는 MSE가 모델의 성능을 왜곡하여 평가할 수 있습니다. MAE는 이러한 이상치에 덜 민감하기 때문에, 모델의 성능을 더 안정적으로 평가할 수 있습니다\n",
    "* (29-4) R²에 대해 설명하고, R² 값이 1, 0, 음수일 때 각각 어떤 의미인지 설명하시오.\n",
    "* 회귀 분석 모델의 성능을 평가하기 위해 사용되는 지표 중 하나로, 모델이 실제 데이터를 얼마나 잘 설명하는지를 나타냅니다. R² 값은 0에서 1 사이의 값을 가지며, 경우에 따라 음수 값이 나올 수도 있습니다\n",
    "* R² = 1: 모델이 실제 데이터를 완벽하게 설명하고 있다는 의미입니다.\n",
    "* R² = 0: 모델이 실제 데이터를 전혀 설명하지 못하고 있다는 의미입니다.모델의 예측 값이 실제 값의 평균과 같을 때, 즉 모델이 단순히 평균 값으로만 예측하는 경우와 같습니다.\n",
    "* R² < 0 (음수): 모델이 실제 데이터보다 더 나쁜 예측을 하고 있다는 의미입니다.이는 모델이 실제 값의 평균으로 예측하는 것보다도 성능이 떨어진다는 것을 나타냅니다. 보통 R²가 음수인 경우는 모델이 매우 부적절하거나, 잘못된 피팅이 이루어진 경우에 발생합니다.\n",
    "* (29-5) 다음 중 MSE의 특징으로 옳지 않은 것은?\n",
    "* (a) 모든 오차의 제곱을 평균한 값이다. (b) 큰 오차에 대해 패널티를 더 많이 부여한다.\n",
    "  (c) 오차의 절댓값을 평균한 값이다. (d) 값이 작을수록 모델의 예측 성능이 좋다는 의미이다.\n",
    "* 정답: (c) c는 MAE의 특성이다.\n",
    "* (29-6) MAE의 장점으로 올바른 것은?\n",
    "* (a) 큰 오차에 대해 더 큰 패널티를 준다. (b) 모든 오차를 제곱하여 계산한다.\n",
    "(c) 이상치에 덜 민감하다. (d) R² 값이 항상 1에 가까워진다.\n",
    "* 정답: (c)\n",
    "* (29-7) R² 값이 0.9인 경우, 모델의 성능에 대해 올바르게 해석한 것은?\n",
    "* (a) 모델이 예측을 완벽하게 수행한다. (b) 모델이 데이터 변동의 90%를 설명한다.\n",
    "(c) 모델이 90%의 데이터를 정확하게 예측한다. (d) 모델이 예측 오차의 90%를 제거한다.\n",
    "* 정답: (b)\n",
    "* (29-8) R² 값이 음수인 경우, 이는 무엇을 의미하는가?\n",
    "* (a) 모델이 예측을 완벽하게 수행한다. (b) 모델이 데이터 변동의 0%를 설명한다.\n",
    "(c) 모델이 상수 모델보다 성능이 낮다. (d) 모델이 예측 오차의 100%를 제거한다\n",
    "* 정답: (c)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7742bb-0185-4b0f-88fe-72130284ecc1",
   "metadata": {},
   "source": [
    "# 30번\n",
    "* 다음은 회귀 분석에 관한 문제에 대해 답하시오.\n",
    "* (30-1) 다음 중 선형 회귀 분석의 기본 가정에 해당하지 않는 것은?\n",
    "* (a) 선형성 (Linearity) (b) 독립성 (Independence)\n",
    "(c) 정규성 (Normality) (d) 이산성 (Discreteness)\n",
    "* 정답: (d)\n",
    "* (30-2) 회귀분석의 정의가 올바르지 않은 것은?\n",
    "* (a) 1개 또는 그 이상의 독립변수들이 종속변수에 미치는 영향을 추정할 수 있는 머신러닝기\n",
    "법이다.\n",
    "* (b) 변수들 사이의 상관관계를 밝히고 모형을 적합하여 관심이 있는 변수를 예측하거나 추론\n",
    "하기 위한 분석 방법이다.\n",
    "* (c) 독립변수의 개수가 1개이면 단순 선형회귀분석, 독립변수의 개수가 두 개 이상이면 다중\n",
    "선형회귀분석으로 분석할 수 있다.\n",
    "* (d) 회귀분석에서 Python의 통계 모델을 구축하고 평가하는 데 사용되는 statsmodels의\n",
    "OLS(Ordinary Least Squares) 모델을 사용하여 선형 회귀 분석을 수행할 수 있다.\n",
    "* 정답:(a) ??\n",
    "* (30-3) 선형 회귀 모델링의 성능을 평가할 때 사용되는 지표가 아닌 것은?\n",
    "* (a) MSE (b) MAE (c) R² (d) ROC-AUC\n",
    "* 정답: (d) ROC-AUC 는 주로 분류 모델의 성능 평가에 사용되는 지표로, 이진 분류 문제에서 모델의 분류 능력을 평가하는 데 사용\n",
    "* (30-4) 선형 회귀 통계모델의 요약(summary)을 통해 해석할 수 있는 지표가 아닌 것은?\n",
    "* (a) 회귀계수 (b) p-value (c) R-제곱 (d) MSE\n",
    "* 정답: (d) MSE\n",
    "*  단순 선형 회귀분석 통계모델링 OLS에 대한 설명이 올바르지 않은 것은?\n",
    "* (a) 하나의 독립변수가 종속변수에 미치는 영향을 추정할 수 있는 통계기법이다.\n",
    "* (b) 단순 선형 회귀 추정 수식은    이다.\n",
    "* (c) 단순 선형 회귀 수식    의 계수의 p>|t| 값은 일반적으로 0.05보다 작으면\n",
    "해당 회귀계수는 통계적으로 유의미하다고 판단한다.\n",
    "* (d) R-제곱 (R-squared)은 모델의 설명력을 나타낸다. 즉, 독립 변수가 종속 변수의 변동성을\n",
    "얼마나 설명하는지를 보여준다.\n",
    "* (e) R-제곱 값이 1에 가까울수록 모델이 데이터를 잘 설명을 못함을 의미한다.\n",
    "* (f) 회귀계수의 추정은 최소제곱법, 즉 잔차제곱합이 가장 작은 선을 구하는 것을 의미한다.\n",
    "* (g) 회귀계수가 0이면 입력변수와 종속변수 사이에는 아무런 관계가 없음을 의미한다.\n",
    "* 정답: (e) 1에 가까울 수록 잘 설명함을 의미\n",
    "* (30-6) 다음 OLS 선형회귀 모델링의 요약 결과표이다. 이 표를 보고 이 모델의 성능을 해석\n",
    "하시오:\n",
    "* 모델 정보 및 성능 지표:\n",
    "* OLS Regression Results\n",
    "* ---------------------------\n",
    "* Dep. Variable: 매출액\n",
    "* Model: OLS\n",
    "* Method: Least Squares\n",
    "* Date: Tue,10 Jun 2024\n",
    "* Time: 12:00:00\n",
    "* No. Observations: 5\n",
    "* Df Residuals: 3\n",
    "* Df Model: 1\n",
    "* Covariance Type: nonrobust\n",
    "* R-squred: 0.988\n",
    "* Adj. R-squared: 0.984\n",
    "* F-statisic: 170.0\n",
    "* Prob(F-statistic): 0.00016\n",
    "* Log-Likelihood: -1.4239\n",
    "* AIC: 6.848\n",
    "* BIC: 6.066\n",
    "* ------------------------------\n",
    "* \tcoef\tstd err\tt\tp>|t|\t[0.025\t0.0975]\n",
    "* ---------------------------------------------------------------\n",
    "* const\t1.9220\t0.186\t10.323\t0.002\t1.343\t2.501\n",
    "* 광고비\t0.6300\t0.048\t12.247\t0.000\t0.486\t0.774\n",
    "* ===============================================================\n",
    "* Dep. Variable: 종속 변수는 '매출액'입니다.\n",
    "* Model: OLS (Ordinary Least Squares) 모델을 사용한 선형 회귀분석입니다.\n",
    "* No. Observations: 총 5개의 관측치가 있습니다.\n",
    "* Df Residuals: 잔차 자유도는 3입니다.\n",
    "* Df Model: 모델의 자유도는 1입니다 (독립 변수가 하나인 단순 선형 회귀).\n",
    "* R-squared (R²): 0.988\n",
    "모델이 종속 변수인 '매출액'의 변동성을 약 98.8% 정도 설명한다는 의미입니다. 높은 R² 값은 모델이 데이터를 잘 설명한다는 것을 나타냅니다.\n",
    "* Adj. R-squared (조정된 R²): 0.984\n",
    "독립 변수의 수와 관측치 수를 고려하여 조정된 R² 값이며, 여기서도 높은 설명력을 보여줍니다.\n",
    "* F-statistic: 170.0\n",
    "회귀 모델의 전체적인 유효성을 평가하는 F-통계량 값입니다. 높은 F-statistic 값은 모델이 유의미하다는 것을 나타냅니다.\n",
    "* Prob(F-statistic): 0.00016\n",
    "F-statistic의 유의확률 값으로, 모델 전체의 유효성에 대한 가설 검정 결과입니다. 매우 낮은 값으로, 모델이 통계적으로 유의미함을 나타냅니다.\n",
    "회귀계수 및 통계적 유의성:\n",
    "\n",
    "* const (상수항): 회귀식에서의 절편 값은 1.9220이며, 표준 오차는 0.186입니다. t-statistic 값은 10.323으로, 이는 통계적으로 매우 유의미한 것을 나타냅니다 (p-value = 0.002).\n",
    "* 광고비: 회귀식에서 '광고비' 독립 변수의 계수는 0.6300이며, 표준 오차는 0.048입니다. t-statistic 값은 12.247로, 이 또한 매우 유의미합니다 (p-value = 0.000).\n",
    "추가 정보:\n",
    "\n",
    "* Log-Likelihood: -1.4239\n",
    "최대 로그 우도 값입니다. 높은 값일수록 모델이 데이터를 잘 설명한다는 것을 의미합니다.\n",
    "* AIC (Akaike Information Criterion): 6.848\n",
    "모델의 복잡성과 성능을 고려한 정보 기준입니다. 낮은 값일수록 더 좋은 모델입니다.\n",
    "* BIC (Bayesian Information Criterion): 6.066\n",
    "AIC와 유사하게 모델 선택 기준으로 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c003c5c-335a-4a6a-a5ff-e9da856f1e48",
   "metadata": {},
   "source": [
    "# 31번 \n",
    "* [코딩 문제] 주어진 데이터를 이용하여 로지스틱 분류 회귀(Logistic regression) 모델링\n",
    "을 코딩하시오. 아래 문제별 코드를 실행하면 로지스틱 회귀 분류 모델링의 각 단계를 확인할\n",
    "수 있도록 코딩하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "435be64b-ff0a-40b9-88b3-5ee5160e0966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient (가중치): [[1.04742396]]\n",
      "Intercept (절편): [-2.53531358]\n",
      "특성 데이터 [6]에 대한 예측 값: 1\n",
      "특성 데이터 [7]에 대한 예측 값: 1\n",
      "Confusion Matrix:\n",
      "[[2]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khgg0\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# (31-1) 주어진 데이터를 사용하여 로지스틱 회귀 모델을 생성하고 지도학습으로 훈련하시오. \n",
    "# (31-2) 문제 (31-1)에서 얻은 로지스틱 분류 모델의 회귀 계수와 y절편을 출력하시오.\n",
    "# (31-3) 주어진 특성 데이터를 사용하여 문제 (31-1)에서 얻은 로지스틱 회귀 모델의 예측 값을 추정하시오\n",
    "# (31-4) 주어진 특성 데이터를 사용하여 문제 (31-1)에서 얻은 로지스틱 회귀 모델의 분류 성능 평가를 confusion matrix와 classification_report을 활용하여 출력하시오.\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "X_train = np.array([[1],[2],[3],[4],[5]])\n",
    "y_train = np.array([0,0,1,1,1])\n",
    "\n",
    "# 로지스틱 분류 회귀 모델 생성\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# 학습된 모델의 회귀 계수(coefficient)와 y절편(intercept) 출력\n",
    "print(\"Coefficient (가중치):\", model.coef_)\n",
    "print(\"Intercept (절편):\", model.intercept_)\n",
    "\n",
    "X_test = np.array([[6],[7]])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_true = np.array([1, 1])\n",
    "\n",
    "# 예측 결과 출력\n",
    "for i, x in enumerate(X_test):\n",
    "    print(f\"특성 데이터 {x}에 대한 예측 값: {y_pred[i]}\")\n",
    "\n",
    "# Confusion Matrix 출력\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Classification Report 출력\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b9ff60-da8b-4322-b574-b35c3b86fecf",
   "metadata": {},
   "source": [
    "# 32번\n",
    "* 영화 평점 이진분류 모델의 테스트 데이터 셋에 대한 혼동 행렬(confusion matrix)이 다음과 같다. 혼동 행렬의 숫자( 테스트 데이터 셋의 샘플 개수)는 다음과 같이 정의한다.\n",
    "* ∙TP (True Positive): 2 (실제 good이며 예측도 good)\n",
    "* ∙FN (False Negative): 1 (실제 good이지만 예측은 bad)\n",
    "* ∙FP (False Positive): 1 (실제 bad이지만 예측은 good)\n",
    "* ∙TN (True Negative): 1 (실제 bad이며 예측도 bad)\n",
    "\n",
    "* (32-1) 혼동 행렬을 사용하여 정확도(accuracy), 정밀도(Precision), 재현율(Recall)를 계산하시오.\n",
    "* 답: (1) 정밀도 : 실제로 양성으로 예측된 샘플 중에서 실제 양성의 비율 :\n",
    "* 답:Precision = TP / (TP+FP) = 2/3\n",
    "* (2) 재현율은 실제 양성 샘플 중에서 양성으로 예측된 샘플의 비율\n",
    "* 답: Recall= TP /(TP+FN) = 2/3\n",
    "* (3) 정확도은 실제 양성 샘플 중에서 양성으로 예측하고, 음성 샘플을 음성으로 예측된 샘플\n",
    "의 비율\n",
    "* 답: Recall= (TP+TN) /(TP+FP+TN+FN) = 3/5\n",
    "\n",
    "* (32-2) 다음 중 영화 평점 분류 모델에서 가장 적절한 평가 지표는?\n",
    "* (a) 정확도 (b) 정밀도 (c) 재현율 (d) F1 점수\n",
    "* 정답: (a) 정확도\n",
    "\n",
    "* (32-3) 다음 중 영화 평점 이진분류 모델에서 재현율이 높은 경우 어떤 상황을 의미하는가요?\n",
    "* (a) 거짓 양성(FP)이 적은 경우 (b) 거짓 음성(FN)이 적은 경우\n",
    "* (c) 실제 양성(TP)이 적은 경우 (d) 실제 음성(TN)이 적은 경우\n",
    "* 정답: 재현율이 높은 경우는 거짓 음성(FN)이 적은 경우를 의미합니다. 재현율은 실제 Positive인 케이스 중에서 모델이 정확히 Positive로 예측한 비율을 나타내므로, 거짓 음성(FN)이 적다는 것은 모델이 실제로 Positive인 경우를 더 잘 잡아내고 있다는 것을 의미합니다.\n",
    "\n",
    "각 옵션별로 설명하면 다음과 같습니다:\n",
    "\n",
    "* (a) 거짓 양성(FP)이 적은 경우: 정밀도가 높은 상황을 의미합니다. 거짓 양성(FP)이 적다는 것은 모델이 Negative로 예측한 경우 대부분이 실제로 Negative인 경우가 많다는 것을 나타냅니다.\n",
    "\n",
    "* (b) 거짓 음성(FN)이 적은 경우: 재현율이 높은 상황을 의미합니다. 거짓 음성(FN)이 적다는 것은 모델이 실제로 Positive인 경우를 더 잘 예측하고 있다는 것을 나타냅니다.\n",
    "\n",
    "* (c) 실제 양성(TP)이 적은 경우: 재현율이 낮은 상황을 의미합니다. 실제 양성(TP)이 적다는 것은 모델이 실제로 Positive인 경우를 놓치는 경우가 많다는 것을 나타냅니다.\n",
    "\n",
    "* (d) 실제 음성(TN)이 적은 경우: 특별한 상황을 나타내지 않으며, 모델의 성능 평가에는 직접적으로 영향을 주지 않습니다.\n",
    "\n",
    "* (32-4) 다음 중 영화 평점 이진분류 모델에서 발생할 수 있는 문제는?\n",
    "* (a) 거짓 음성(FN)이 많은 경우 (b) 거짓 양성(FP)이 많은 경우\n",
    "* (c) 실제 양성(TP)이 많은 경우 (d) 정확도(Accuracy)가 100%인 경우\n",
    "* 정답: (a) 다시 확인하기!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
